{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUDunXR-3YKu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6장 결정트리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 감사의 글\n",
    "\n",
    "자료를 공개한 저자 오렐리앙 제롱과 강의자료를 지원한 한빛아카데미에게 진심어린 감사를 전합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 주요내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBxgwiZb3iHR",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 결정트리 훈련 방법과 시각화\n",
    "* 클래스 예측 및 추정 확률\n",
    "* CART 알고리즘 및 계산 복잡도\n",
    "* 지니 불순도 vs. 엔트로피\n",
    "* 규제 하이퍼파라미터\n",
    "* 결정트리 회귀 모델\n",
    "* 결정트리의 불안정성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjQC0LJV38v0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.1 결정트리 훈련 방법과 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjQC0LJV38v0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런의 결정트리 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjQC0LJV38v0",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 결정트리 방식의 최대 장점: 데이터 전처리 거의 불필요. 필요한 경우도 존재(불안정성 참조)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjQC0LJV38v0",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 사이킷런의 `DecisionTreeClassifier` 모델 활용\n",
    "    * 붓꽃 데이터 활용. 꽃잎의 길이와 너비 기준으로 분류.\n",
    "    * `max_depth=2`: 결정트리의 최대 깊이 지정. \n",
    "        여기서는 최대 2번의 데이터셋 분할 허용. 기본값은 `None`이며 무제한 데이터셋 분할 허용.\n",
    "\n",
    "    ```python\n",
    "    tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "    tree_clf.fit(X, y)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQyfP6CW4zPh",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정트리 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQyfP6CW4zPh",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 사이킷런의 `export_graphviz()` 함수 활용\n",
    "* pdf, png 등 많은 종류의 파일로 변환 가능\n",
    "* __주의사항:__ 파이썬 3.7 버전 사용해야 설치 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"images/ch06/homl06-01.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgctkyUP5LUL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 트리 구성 요소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgctkyUP5LUL",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 노드(node): 가지 분할이 시작되는 지점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgctkyUP5LUL",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 루트 노드(root node): 맨 상단에 위치한 노드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgctkyUP5LUL",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 리프 노드(leaf node): 더 이상의 가지분할이 발생하지 않는 노드. 즉, 자식 노드가 없는 노드."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정트리 노드의 속성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `gini`: 해당 노드의 지니 불순도 측정값\n",
    "    * 모든 샘플이 동일 클래스에 속하면 불순도가 0이 됨. 즉, `gini=0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `samples`: 해당 노드에 포함된 샘플 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `value`: 해당 노드에 포함된 샘플들의 실제 클래스별 개수. 타깃 정보 활용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `class`: 각 클래스별 비율을 계산하여 가장 높은 비율에 해당하는 클래스 선정\n",
    "  * 동일한 비율이면 낮은 인덱스 선정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYcae39N5kQ2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.2 클래스 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 꽃잎 길이와 너비: 각각 5cm, 1.5cm\n",
    "\n",
    "* 데이터가 주어지면 루트에서 시작\n",
    "\n",
    "* 분할 1단계: 꽃잎 길이가 2.45cm 이하가 아니기에 오른편으로 이동.\n",
    "\n",
    "* 분할 2단계: 꽃잎 너비가 1.75cm 이하이기에 왼편으로 이동. 버시컬러로 판정."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정경계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "아래 그림은 `max_depth=3`으로 지정해서 학습한 결정트리의 결졍경계를 보여준다. \n",
    "\n",
    "* 1차 분할 기준: 꽃잎 길이 2.45cm\n",
    "* 2차 분할 기준: 꽃잎 너비 1.75cm\n",
    "* 3차 분할 기준: 꽃잎 길이 4.85cm와 4.95cm\n",
    "    - 우상단 화살표가 가리키는 점, 세모와 네모가 겹쳐있음. 이 경우 과대적합으로 보아야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"images/ch06/homl06-02a.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.3 클래스 추정 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 클래스에 속할 확률 추정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 주어진 샘플에 대해 예측된 노드에 속한 샘플들의 클래스별 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 예제: 꽃잎 길이와 너비가 각각 5cm, 1.5cm인 붓꽃에 대한 클래스 추정 확률은 깊이 2의 왼편 노드에 \n",
    "    포함된 샘플들의 클래스별 비율에서 최댓값으로 계산됨. 즉, 버시컬러에 속할 확률이 90.7%임.\n",
    "    \n",
    "$$0.907 = \\max([ 0/54, 49/54, 5/54])$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* __참고:__ 동일한 노드에 속한 샘플에 대한 추정 확률은 언제나 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.4 결정트리 훈련 알고리즘: CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5K56v6g7sJT",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 지니 불순도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5K56v6g7sJT",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 불순도\n",
    "\n",
    "    $$G_i = 1 - \\sum_{k=1}^{K} {p_{i,k}}^2$$\n",
    "    \n",
    "    여기서 $p_{i,k}$는 $i$ 번째 노드에 있는 훈련 샘플 중 클래스 $k$에 속한 샘플의 비율임. $K$는 클래스의 수."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5K56v6g7sJT",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 예제: 깊이 2의 왼편 노드의 지니 불순도는 0.168임.\n",
    "\n",
    "$$G_4 = 1 - (0/54)^2 - (49/54)^2 - (5/54)^2 = 0.168$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CART(Classification and Regression Tree) 분류 알고리즘의 비용함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 각 노드에서 아래 비용함수를 최소화 하는 특성 $k$와 해당 특성의 임곗값 $t_k$을 결정해서 사용함.\n",
    "    - $m$, $m_\\text{left}$, $m_\\text{right}$: 각각 \\부모와 자식 노드에 속한 샘플 수\n",
    "    - $G_\\text{left}$, $G_\\text{right}$: 두 자식 노드의 지니 불순도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "J(k, t_k) = \\frac{m_\\text{left}}{m}\\, G_\\text{left} + \\frac{m_\\text{right}}{m}\\, G_\\text{right}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $J(k, t_k)$가 작을수록 불순도가 낮은 두 개의 부분집합으로 분할됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* __참고__: 탐욕적 알고리즘 사용. 해당 노드를 기준으로 지니 불순도가 가장 낮은, 즉, 가장 순수한(pure) 두 개의 부분집합으로 분할함.\n",
    "    최적의 분할이란 보장은 없지만 일반적으로 적절한 성능을 보임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 분할 과정 반복: `max_depth` 등 규제의 한계에 다다르거나 더 이상 불순도를 줄이는 분할이 불가능할 때까지 진행."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.5 CART 알고리즘의 계산 복잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 최적의 결정트리 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 최적의 결정트리를 찾는 문제는 NP-완전(NP-complete)임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 이런 문제의 시간 복잡도는 $O(\\exp(m))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 즉, 매우 작은 훈련 세트에 대해서도 제대로 적용하기 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정트리 모델의 예측 시간 복잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 학습된 결정트리가 예측에 필요한 시간: $O(\\log m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 훈련 샘플 수 $m$에만 의존하며 매우 빠름. \n",
    "    각 노드에서 하나의 특성만 분류기준으로 사용되기에 특성 수와 무관하기 때문임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CART 알고리즘의 시간 복잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 훈련 샘플이 크기순으로 정렬된 경우 ($n, m$은 각각 특성 개수와 샘플 개수를 나타냄):\n",
    "    * 각 노드에서 분류하는 데 걸리는 시간: $O(n\\cdot m\\cdot \\log(m))$\n",
    "    * 결정트리를 완성하는 데 걸리는 시간: $O(n\\cdot m^2\\cdot \\log(m))$ \n",
    "    * 규제가 있는 경우 좀 더 빨라짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `DecisionTreeClassifier`의 `presort=True` 옵션 설정: 훈련 세트를 먼저 정렬시킨 후 훈련 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 훈련 세트의 크기가 몇 천보다 크면 정렬 자체가 오래 걸림. 가장 빠른 정렬 알고리즘의 복잡도가 $O(m\\log m)$ 정도임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaVDK_hy___q",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.6 지니 불순도 vs. 엔트로피"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 엔트로피 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaVDK_hy___q",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `DecisionTreeClassifier`의 `criterion=\"entropy\"` 옵션 설정: \n",
    "    * gini 불순도 대신에 샘플들의 __무질서__ 정도를 측정하는 엔트로피 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaVDK_hy___q",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 특정 노드의 엔트로피($H$) 계산\n",
    "\n",
    "$$H_i = -\\sum_{\\substack{k=1\\\\p_k\\neq 0}}^{K} p_{k}\\, \\log(p_k)$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaVDK_hy___q",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 지니 불순도를 사용할 때와 비교해서 큰 차이가 나지 않음.\n",
    "    다만, 엔트로피 방식이 노드를 보다 균형 잡힌 두 개의 자식 노드로 분할함.\n",
    "    하지만 지니 불순도 방식이 보다 빠르게 훈련되며 따라서 기본값으로 사용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 엔트로피 방식의 장점 발생 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaVDK_hy___q",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "& \\text{특정 $k$에 대해 $p_k$가 0에 매우 가까운 경우} \\\\\n",
    "&\\quad\\Rightarrow \\text{$-\\log(p_k)$가 매우 커짐} \\\\\n",
    "&\\quad\\Rightarrow \\text{엔트로피 증가} \\\\\n",
    "&\\quad\\Rightarrow \\text{비용함수 $J(k, t_k)$ 증가} \\\\\n",
    "&\\quad\\Rightarrow \\text{그런 조합은 피하게 됨} \\\\\n",
    "&\\quad\\Rightarrow \\text{보다 균형 잡힌 두 개의 부분집합으로 분할하는 방향으로 유도}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.7 규제 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 비파라미터 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 결정트리 모델은 데이터에 대한 어떤 가정도 하지 않음. \n",
    "    - 예를 들어, 노드를 분할할 수 있는 자유도(degree of freedom)에 대한 제한이 기본적으로 없음.\n",
    "    - 반면에 선형 모델 등은 데이터가 선형 모델을 따른다는 가정 등을 함. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 이런 모델을 비파라미터 모델이라 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 과대적합 위험 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런  `DecisionTreeClassifier` 규제하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `max_depth`: 결정트리의 최대 높이 제한"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `min_samples_split`: 노드를 분할하기 위해 필요한 최소 샘플 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `min_samples_leaf`:리프 노드에 포함되어야 하는 최소 샘플 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `min_weight_fraction_leaf`: \n",
    "    * 샘플 별로 가중치가 설정된 경우: 가중치의 전체 합에서 해당 리프 노드에 포함된 샘플의 가중치의 합이 차지하는 비율\n",
    "    * 샘플 별로 가중치가 없는 경우: `min_samples_leaf`와 동일한 역할 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* `max_leaf_nodes`: 허용된 리프 노드의 최대 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `max_features`: 각 노드에서 분할 평가에 사용될 수 있는 최대 특성 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 규제를 높이는 방법\n",
    "    * `min_` 접두사 사용 규제: 값을 키울 것\n",
    "    * `max_` 접두사 사용 규제: 값을 감소시킬 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런  `DecisionTreeClassifier` 규제 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oeGK7R0rCP_I",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 예제: `moons` 데이터셋에 대한 결정트리 모델 학습\n",
    "    * 왼편: 규제 전혀 없음. 보다 정교하며 과대적합됨.\n",
    "    * 오른편: `min_samples_leaf=4`. 일반화 성능이 보다 좋음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"images/ch06/homl06-03.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31HcJrG8DBbP",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.8 (결정트리) 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ta34qi8vDKE1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런의 `DecisionTreeRegressor` 예측기 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31HcJrG8DBbP",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 결정트리 알고리즘 아이디어를 거의 그대로 이용하여 회귀 문제에 적용 가능\n",
    "\n",
    "    ```python\n",
    "    tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "    tree_reg.fit(X, y)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 예제: 잡음이 포함된 2차 함수 형태의 데이터셋\n",
    "    * 왼편: `max_depth=2`\n",
    "    * 오른편: `max_depth=3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"images/ch06/homl06-04.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 왼편 그림 설명\n",
    "\n",
    "<div align=\"center\"><img src=\"images/ch06/homl06-05.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdPEwMOKD2Ts",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 각 노드에 포함된 속성\n",
    "  * `samples`: 해당 노드에 속한 훈련 샘플 수\n",
    "  * `value`: 해당 노드에 속한 훈련 샘플의 평균 타깃값\n",
    "  * `mse`: 해당 노드에 속한 훈련 샘플의 평균제곱오차(MSE)\n",
    "    * 오차 기준은 `value` 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Wv-PadWE4su",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 회귀용 CART 알고리즘과 비용함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 분류의 경우처럼 탐욕적으로 아래 비용함수를 최소화 하는 특성 $k$와 해당 특성의 임곗값 $t_k$을 결정함:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "J(k, t_k) &= \\frac{m_\\text{left}}{m}\\, \\text{MSE}_\\text{left} + \\frac{m_\\text{right}}{m}\\, \\text{MSE}_\\text{right} \\\\[2ex]\n",
    "\\text{MSE}_\\text{node} &= \\sum_{i\\in \\text{node}} (\\hat y_{node} - y^{(i)})^2\\\\[1ex]\n",
    "\\hat y_\\text{node} &= \\frac{1}{m_\\text{node}} \\sum_{i\\in\\text{node}} y^{(i)}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $\\text{MSE}_\\text{left}$($\\text{MSE}_\\text{right}$):\n",
    "    지정된 특성 $k$와 특성 임곗값 $t_k$로 구분된 왼편(오른편) 부분집합의 평균제곱오차\n",
    "    * 해당 노드에 속한 샘플들의 평균 타깃값 기준\n",
    "    * $m_\\text{left}$/$m_\\text{right}$: 해당 노드에 속하는 샘플 수\n",
    "    * $y^{(i)}$: 샘플 $i$에 대한 실제 타깃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5CYDKUtFn3b",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5CYDKUtFn3b",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 분류의 경우처럼 규제가 없으면 과대적합 발생할 수 있음.\n",
    "\n",
    "* 왼편: 규제가 없는 경우. 과대적합 발생\n",
    "    \n",
    "* 오른편: `min_samples_leaf=10`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"images/ch06/homl06-06.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gppqltl-F3Rc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.9 (결정트리) 불안정성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 단점 1: 훈련 세트 회전 민감도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gppqltl-F3Rc",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 결정트리 알고리즘은 성능이 매우 우수하지만 기본적으로 주어진 훈련 세트에 민감하게 반응함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gj6GGfQyGDCL",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 결정트리는 항상 축에 수직인 분할을 사용. 따라서 조금만 회전을 가해도 결정 경계가 많이 달라짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gj6GGfQyGDCL",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 예제: 오른편 그래프: 왼편 그래프를 45도 회전시킨 훈련 세트 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"images/ch06/homl06-07.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gj6GGfQyGDCL",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* PCA 기법 등을 사용하여 훈련 샘플 회전시킨 후 학습 가능. (8장 참조)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8y7IjEKKGd4j",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 단점 2: 훈련 세트 변화 민감도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 훈련 데이터의 작은 변화에도 매우 민감함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8y7IjEKKGd4j",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 예제: 붓꽃 데이터에서 하나의 샘플을 제거한 후 학습시킬 때 매우 다르게 학습할 수 있음.\n",
    "    * 왼편 그래프: 모든 샘플 대상 훈련\n",
    "    * 오른편 그래프: 가장 넓은 버시컬러 샘플 제거 후 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch06/homl06-08c.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 많은 트리에서 만든 예측값의 평균을 활용 추천(7장 램덤포레스트 모델 참조)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "핸즈온머신러닝_6장.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
