{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 10장 케라스를 사용한 인공신경망 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 감사의 글\n",
    "\n",
    "자료를 공개한 저자 오렐리앙 제롱과 강의자료를 지원한 한빛아카데미에게 진심어린 감사를 전합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 인공신경망\n",
    "    * 딥러닝의 핵심\n",
    "    * 강력하며 확장성이 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 인공신경망의 응용: 대규모 머신러닝 문제 다루기에 적합\n",
    "    * 구글 이미지: 수백만 개의 이미지 분류\n",
    "    * 애플의 시리: 음성인식 서비스\n",
    "    * 유튜브: 가장 좋은 비디오 추천\n",
    "    * 딥마인드의 알파고: 스스로 기보를 익히면서 학습하는 바둑 프로그램"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 퍼셉트론\n",
    "    * 가장 단순한 인공신경망 구조 중 하나\n",
    "    * 프랑크 로젠블라트가 1957년에 발표."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 주요 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYbSTqz67D9H",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 퍼셉트론 소개\n",
    "* 다층 퍼셉트론과 역전파\n",
    "* 케라스(keras)를 이용한 다층 퍼셉트론 구현\n",
    "* 텐서보드를 활용한 시각화\n",
    "* 신경망 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-Y7yrhc7cM6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 퍼셉트론 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* TLU(threshold logic unit) 또는 LTU(linear threshold unit) 라 불리는 인공 뉴런 활용\n",
    "* 입력/출력: 숫자\n",
    "* 모든 입력은 가중치와 연결됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 입력값과 가중치를 곱한 값들의 합에 계단함수(step function) 적용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "z &= {\\mathbf x}^T {\\mathbf w} \\\\\n",
    "  &= x_1 w_1 + x_2 w_2 + \\cdots + x_n w_n \\\\\n",
    "  & \\\\\n",
    "h_\\mathbf{w}(\\mathbf x) &= step(z)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $n$: 특성 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3개의 특성을 갖는 샘플 하나가 입력되면 가중치와 곱한 후 합을 계산\n",
    "* 이후 계단함수를 통과시킨 결과를 출력\n",
    "* 보통은 편향에 대한 가중치고 함께 고려. (잠시 뒤에 설명)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-01.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 계단함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 가장 많이 사용되는 계단함수: Heaviside 계단함수와 sign 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\mathrm{heaviside}(z) = \n",
    "\\begin{cases}\n",
    "0 & \\text{ if } z < 0\\\\\n",
    "1 & \\text{ if } z \\ge 0\n",
    "\\end{cases}\n",
    "\\quad\\qquad\n",
    "\\mathrm{sgn}(z) = \n",
    "\\begin{cases}\n",
    "-1 & \\text{ if } z < 0\\\\\n",
    "0 & \\text{ if } z = 0\\\\\n",
    "1 & \\text{ if } z > 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TLU와 선형 이진분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 하나의 TLU를 간단한 이진분류기로 활용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모든 입력값(특성)의 선형 조합을 계산한 후에 임곗값을 기준으로 양성/음성 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 작동은 로지스틱 회귀 또는 선형 SVM 분류기와 비슷."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TLU 모델 학습 = 최적의 가중치 $w_i$를 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 퍼셉트론 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 하나의 층에 여러 개의 TLU로 구성됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TLU 각각은 모든 입력과 연결됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 입력층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 입력 뉴런으로 구성된 층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 입력 뉴런: 입력을 받아 그대로 통과시켜 출력하는 뉴런"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 편향값 1을 항상 출력하는 편향 뉴런과 여러 개의 입력 뉴런이 함께 사용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 입력 두 개와 출력 세 개로 구성된 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-02.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 퍼셉트론 학습 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 오차가 감소되도록 가중치를 조절하며 뉴런 사이의 관계를 강화시킴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 하나의 샘플이 입력될 때 마다 예측한 후에 오차를 계산하여 오차가 줄어드는 방향으로 가중치 조절."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{i, j}^{(\\text{next step})} = \n",
    "w_{i, j} + \\eta\\, (y_j - \\hat y_j)\\, x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "w_{i, j}^{(\\text{next step})} = \n",
    "w_{i, j} + \\eta\\, (y_j - \\hat y_j)\\, x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $w_{i, j}$: 가중치 행렬 $W$의 $i$행 $j$열의 값."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $x_{i}$: 입력 샘플의 $i$번째 속성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\hat y_{j}$: $j$번째 출력값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $y_{j}$: $j$번째 출력값에 대한 타깃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\eta$: 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 퍼셉트론과 선형성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 각 출력 뉴런의 결정경계가 선형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 따라서 퍼셉트론도 복잡한 패턴 학습 못함. 하지만 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 퍼셉트론 수렴 이론: 선형적으로 구분될 수 있는 모델은 언제나 학습 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런의 퍼셉트론 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perceptron 클래스 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 예제: 붓꽃 데이터셋 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-07.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 퍼셉트론의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아래 옵션을 사용할 경우 SGDClassifier 와 동일하게 작동\n",
    "\n",
    "    * `loss=\"perceptron\"`\n",
    "    * `learning_rate=\"constant\"`\n",
    "    * `eta0=1, penalty=None`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 클래스 확률 지원 없음. 따라서 로지스틱 회귀가 보다 선호됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 퍼셉트론은 매우 단순한 경우만 해결 가능. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 하지만 퍼셉트론을 여러 개 쌓아올리면 꽤 강력한 인공신경망 구성함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 다층 퍼셉트론(MLP)과 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 다층 퍼셉트론(multilayer perceptron, MLP): 퍼셉트론을 여러 개 쌓아올린 인공신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 구성은 다음과 같음.\n",
    "\n",
    "    * 한 개의 입력층\n",
    "    * 여러 개의 은닉층\n",
    "    * 한 개의 출력층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-08.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 완전연결 층(밀집 층)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 층에 속한 각각의 뉴런이 이전 층의 모든 뉴런과 연결되어 있을 때를 가리킴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 예제: 퍼셉트론의 출력층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 완전연결 층의 출력 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 여러 개의 완전연렬 층으로 구성된 다층 퍼셉트론 모델의 일반적인 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-04.png\" width=\"350\"/>\n",
    "\n",
    "<그림 출처: [netclipart](https://www.netclipart.com/down/ihwJhJh_angle-symmetry-area-neural-networks-transparent-backgrounds/)>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 이 중에서 아래 빨간색으로 이루어진 부분에 대한 계산은 어떻게?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-05.png\" width=\"350\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 다음과 같이 이루어짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-03.png\" width=\"400\"/>\n",
    "\n",
    "<그림 출처: [medium](https://medium.com/@jayeshbahire/the-artificial-neural-networks-handbook-part-4-d2087d1f583e)>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 하나의 층에서 이루어지는 입력과 출력을 행렬 수식으로 표현 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-06.png\" width=\"350\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "\\begin{align*}\n",
    "h_{\\mathbf{w},\\mathbf{b}}(\\mathbf X) = \\phi({\\mathbf X}{\\mathbf W} + {\\mathbf b})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\\begin{align*}\n",
    "h_{\\mathbf{w},\\mathbf{b}}(\\mathbf X) = \\phi({\\mathbf X}{\\mathbf W} + {\\mathbf b})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $\\mathbf X$: 입력 샘플들의 특성행렬. \n",
    "    * 각 행은 샘플을 가리킴\n",
    "    * 각 열은 특성을 가리킴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\mathbf W$: 편향 뉴런을 제외한 모든 뉴런에 대한 가중치.\n",
    "    * 각 행은 하나의 입력과 연관됨\n",
    "    * 각 열은 하나의 출력과 연관됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\mathbf b$: 편향벡터\n",
    "    * 편향 뉴런과 연결된 각각의 출력에 대한 편향값으로 구성된 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\phi$: 활성화 함수(activation function)\n",
    "    * 퍼셉트론 모델처럼 각 인공뉴런이 TLU인 경우, 계단함수가 사용됨. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 심층신경망(DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 여러 개의 은닉층을 쌓아올린 인공신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 역전파 훈련 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다층 퍼셉트론은 층이 많을 수록 훈련시키는 과정이 점점 더 어려워짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 1986년에 소개된 역전파(backpropagation) 훈련 알고리즘이 발표된 이후로 실용성 갖춤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 1단계(정방향): 각 훈련 샘플에 대해 먼저 예측을 만든 후 오차 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 2단계(역방향): 역방향으로 각 층을 거치면서 각 연결이 오차에 기여한 정도 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 3단계: 오차가 감소하도록 모든 가중치 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MLP 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 랜덤하게 설정함. 그렇지 않으면 층의 모든 뉴런이 동일하게 움직임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 활성화 함수: 보통 계단함수 대신에 다른 함수 사용.\n",
    "    * 로지스틱(시그모이드)\n",
    "    * 하이퍼볼릭 탄젠트 함수(쌍곡 탄젠트 함수)\n",
    "    * ReLU 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-09.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 활성화 함수 대체 필요성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 선형성을 벗어나기 위해.\n",
    "    * 선형 변환을 여러 개 연결 해도 선형 변환에 머무름.\n",
    "    * 따라서 복잡한 문제 해결 불가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 비선형 활성화 함수를 충분히 많은 층에서 사용하면 매우 강력한 모델 학습 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 회귀를 위한 MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 출력 뉴런 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 예측해야 하는 값의 수에 따라 출력 뉴런 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 예제 1: 주택 가격 예측 \n",
    "    * 출력 뉴런 1개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 예제 2: 다변량 회귀(동시에 여러값 예측하기)\n",
    "    * 출력 차원마다 출력 뉴런 1개\n",
    "    * 예를 들어, 물체의 중심 위치를 알아내려면 좌표 2개 각각에 해당하는 출력 뉴런 2개 필요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 활성화 함수 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 출력값에 특별한 제한이 없다면 활성화 함수 사용하지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 출력이 양수인 경우\n",
    "    * ReLU 또는 softplus 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-10.png\" width=\"350\"/>\n",
    "\n",
    "<그림 출처: [위키피디아](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 출력이 특정 범위 안에 포함되어야 할 경우\n",
    "    * 로지스틱 함수 또는 하이퍼볼릭 탄젠트 함수와 적절한 스케일 조정 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 손실함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 일반적으로 평균제곱오차(MSE) 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 이상치가 많을 경우: 평균절댓값오차(MAE) 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 후버(Huber) 손실 사용 가능\n",
    "    * MSE와 MAE의 조합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 회귀 MLP의 전형적인 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 하이퍼파라미터 | 일반적으로 사용되는 값 |\n",
    "| :--- | :---|\n",
    "| 입력뉴런 수| 샘플의 특성마다 하나 |\n",
    "| 은닉층 수 | 문제에 따라 다름. 보통 1-5개 |\n",
    "| 은닉층의 뉴런 수 | 문제에 따라 다름. 보통 10-100개 |\n",
    "| 출력뉴런 수 | 예측 차원마다 하나 |\n",
    "| 은닉층의 활성화 함수 | ReLU 또는 SELU(11장 참조) |\n",
    "| 출력층의 활성화 함수 | 보통 없음. 상황에 따라 ReLU/softplus 또는 logistic/tanh 사용 |\n",
    "| 손실함수 | MSE 또는 MAE/Huber(이상치 많은 경우) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 분류를 위한 다층 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 이진분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 하나의 출력 뉴런 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 활성화 함수: 로지스틱 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 다중레이블 이진분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다층 퍼셉트론 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 예제 1: 이메일의 스팸 여부와 함께 긴급메일 여부 확인 가능\n",
    "    * 활성화 함수: 두 뉴런 모두 로지스틱 함수 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 예제 2: 다중 클래스 분류\n",
    "    * 3개 이상의 클래스 중 하나의 클래스에만 속해야 하는 경우\n",
    "    * 예를 들어, MNIST 숫자 이미지. 0부터 9까지.\n",
    "    * 클래스마다 하나의 뉴런 사용\n",
    "    * 출력층 활성화 함수: 소프트맥스 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-11.png\" width=\"350\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 손실함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 크로스 엔트로피(로그 손실). 4장 참조."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 분류 MLP의 전형적인 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 하이퍼파라미터 | 이진 분류 | 다중레이블 분류 | 다중클래스 분류 |\n",
    "| :--- | :---| :---| :---|\n",
    "| 입력층과 은닉층 | 회귀와 동일 | 회귀와 동일 | 회귀와 동일 |\n",
    "| 출력뉴런 수 | 1개 | 레이블 당 1개 | 클래스 당 1개 |\n",
    "| 출력층의 활성화 함수 | 로지스틱 함수 | 로지스틱 함수 | 소프트맥스 함수 |\n",
    "| 손실함수 | 크로스 엔트로피 | 크로스 엔트로피 | 크로스 엔트로피 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 텐서플로 플레이그라운드 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [텐서플로 플레이그라운드](https://playground.tensorflow.org) 를 이용한 이진 분류기 훈련해볼 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 케라스(keras)를 이용한 MLP 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* [케라스](https://keras.io)는 모든 종류의 신경망을 손쉽게 만들어 주는 최상위 API 제공."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 멀티 백엔드 케라스: \n",
    "    * 구글의 텐서플로(Tensorflow), \n",
    "    * MS의 Cognitive Toolkit(CNTK), \n",
    "    * Theano(시애노)\n",
    "    * 아파치 MXNet\n",
    "    * 애플 Core ML\n",
    "    * 자바스크립트, 타입스크립트: 웹브라우저에서 케라스 실행 가능\n",
    "    * PlaidML: 모든 종류의 GPU에서 실행 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### tensorflow.keras\n",
    "\n",
    "* 텐서플로만 지원하는 keras 백엔드\n",
    "* 책에서 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-12.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 파이토치(PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [파이토치](https://pytorch.org)는 keras와 비슷한 API 제공하며, 쉽게 배울 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* keras만큼 인기 좋음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 케라스 Sequential 클래스 활용: 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 패션 MNIST 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 10개의 클래스로 이루어짐.\n",
    "\n",
    "* 데이터 셋: 28x28 픽셀 크기의 흑백 패션 이미지 샘플 70,000개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-13.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 모델 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Sequential` 클래스 내에 층을 쌓아 순차적 학습 지원\n",
    "* 은닉층: 2개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 아래 방식도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 아래 명령어를 사용하면 모델 선언된 모델 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-14.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 모델 컴파일하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델을 생성하려면 선언된 모델을 컴파일 해야함.\n",
    "* 손실함수, 옵티마이저, 평가기준 등을 지정해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 모델 훈련과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 훈련: fit 메서드 호출\n",
    "* 평가 동시진행 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 모델 학습 곡선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 훈련된 모델이 반환하는 History 객체의 history 속성에 학습된 에포크의 손실과 정확도 기록됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"keras_learning_curves_plot\")\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-15.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 모델 성능 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 훈련된 모델의 `evaluate` 메서드 활용\n",
    "* 손실과 정확도 계산해줌.\n",
    "* 아래 코드 실행결과: 손실은 0.3339, 정확도는 0.8851"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.evaluate(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 모델 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 훈련된 모델을 이용한 예측은 `predict` 또는 `predict_class` 메서드 활용.\n",
    "* `predict` 메서드: 각 클래스에 속할 확률 계산\n",
    "* `predict_class`: 가장 높은 확률의 클래스 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 케라스 Sequential 클래스 활용: 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 캘리포니아 주택가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Sequential` 클래스를 이용한 회귀용 MLP 구축은 분류용과 기본적으로 동일."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 차이점:\n",
    "    * 출력층에 활성화함수 사용하지 않는 하나의 뉴런만 사용.\n",
    "        * 일반적으로는 예측값의 수 만큼 출력뉴런 사용\n",
    "    * 손실함수: 평균제곱오차(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 캘리포니아 데이터셋과 관련된 주의할 점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 잡음이 많음.\n",
    "* 따라서 과대적합을 줄이기 위해 뉴런 수가 적은 하나의 은닉층만 사용.\n",
    "* 이유: 은닉층과 뉴런이 많이 사용될 수록 가중치 파라미터의 수가 증가하여 과대적합 위험도 커짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 모델 생성, 훈련 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 학습 곡선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-16.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 케라스 Sequential 클래스 활용의 장단점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 사용하기 매우 쉬우며 성능 우수함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 입출력이 여러 개이거나 더 복잡한 네트워크를 구성하기 어려움."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* `Sequential` 클래스 대신에 __함수형__ API, __하위클래스(subclassing)__ API 등을 사용하여 보다 복잡하며, 보다 강력한 딥러닝 모델 구축 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 케라스 함수형 API 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 모든 레이블을 순차적으로 처리하는 것 대신 다양한 신경망 구축을 위해 함수형 API 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 예제: 와이드&딥(Wide & Deep) 신경망. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-17.png\" width=\"700\"/>\n",
    "\n",
    "<그림 출처: [Heng-Tze Cheng et al., \"Wide & Deep Learning for Recommender Systems\"](https://arxiv.org/pdf/1606.07792.pdf)>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 와이드&딥 신경망: 활용 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 깊게 쌓은 층을 사용한 복잡한 패턴과 짧은 경로를 사용한 간단한 규칙 모두 학습가능한 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-18.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 예제: 캘리포니아주 주택가격 데이터셋 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `input_`: `Input` 객체\n",
    "    * `hideen1`을 통해 `hidden2` 로 전달됨\n",
    "    * 반면에 `concat`를 통해 `hidden2`의 결과와 함께 `output`으로 직접 전달되기도 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 와이드&딥 신경망: 활용 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 다중 입력 사용\n",
    "    * 특성을 나누어 짧 경로와 깊은 경로에 (중복을 허용하여) 특성을 나누어 보낼 수도 있음. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-19.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* `input_A`: 5개의 특성 입력받을 수 있음\n",
    "* `input_B`: 6개의 특성 입력받을 수 있음\n",
    "* 입력 뉴런마다 입력값 지정하여 학습해야 함. \n",
    "    * `evaluate()`, `preict()` 메서드를 호출할 때도 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* `input_A` 입력값: 0-4번 인덱스 특성\n",
    "* `input_B` 입력값: 2-7번 인덱스 특성\n",
    "* 중복: 2-4번 인덱스 특성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 와이드&딥 신경망: 활용 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 다중 출력이 필요한 경우 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-20.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* `output`: 주 출력\n",
    "* `aux_output`: 보조 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 컴파일할 때 각 출력 뉴런마다 손실함수 지정해야 함\n",
    "* 출력 별로 __손실가중치__ 를 지정하여 출력별 중요도 지정 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1],\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 모델 훈련 시 출력별로 레이블 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 동적 모델 생성: 하위클래스(subclassing) API 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* `Sequential` 클래스와 함수형 API 방식을 사용한 모델은 모두 정적임.\n",
    "    * 한 번 선언되면 변경할 수 없는 모델 생성\n",
    "    * 모델 저장, 복사, 공유 용이\n",
    "    * 모델 구조 출력 및 모델 분석 용이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 반복문, 조건문 등을 활용하여 동적 모델을 생성하고자 할 경우 명령형프로그래밍 방식 요구됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 하위클래스 API을 활용하여 동적 모델 생성 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 하위클래스 API 활용 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* `Model` 클래스 상속\n",
    "    * 초기설정 메서드(`__init__()`)를 이용하여 은닉층과 출력층 설정\n",
    "    * `call()` 메서드를 이용하여 층을 동적으로 구성 가능\n",
    "        * for 반복문, if 조건문, 텐서플로 저수준 연산 등을 임의로 활용 가능\n",
    "    * 참조: 12장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 단점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 모델 구조가 `call()` 메서드 안에 숨겨져 있어서, 케라스가 분석하기 어려움\n",
    "* 즉, 모델 저장 및 복사 불가능.\n",
    "* `summary()` 메서드 활용 제한됨: 층의 목록만 확인 가능하며, 층간의 연결정보 알 수 없음.\n",
    "* 케라스가 타입과 크기를 미리 확인할 수 없어 실수 발생 많아질 수 있음.\n",
    "* 높은 유연성이 필요하지 않다면 추천하지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Sequential 모델과 함수형 API 를 사용해서 훈련된 모델 저장은 매우 간단함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "model = keras.models.Sequential([...])\n",
    "model.compile([...])\n",
    "model.fit([...])\n",
    "model.save(\"my_keras_model.ht\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 저장된 모델을 복원하려면 `load_model()` 함수 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "model = keras.models.load_model(\"my_keras_model.ht\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 주의사항\n",
    "    * 서브클래스 API 에서는 사용 불가\n",
    "    * `save_weights()`, `load_weights()` 메서드를 활용하여 모델 파라미터만 저장/복원 가능\n",
    "    * 나머지는 수동으로 처리. 예를 들어, `pickle` 모듈 활용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 콜백함수 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 훈련의 시작/끝/중간에 호출할 객체를 콜백함수를 이용하여 지정 가능\n",
    "* 지정된 객체가 호출되면서 각자의 역할 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제: ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 훈련 중에 일정 간격으로 모델의 체크포이트 저장\n",
    "\n",
    "* 체크포인트: 텐서플로우에서 모델 파라미터를 저장하는 양식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "# 모델 생성 후 훈련하기\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.hs\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* `save_best_only=True` 옵션 설정\n",
    "    * 훈련 도중에 검증세트를 사용할 경우 최상의 검증 세트 파라미터 저장 가능\n",
    "\n",
    "* 훈련 종료 후 저장된 최적 모델 복원에 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.hs\",\n",
    "                                                save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10, \n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "\n",
    "# 최적 모델 복원\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제: EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 조기종료 구현 용도로 활용\n",
    "* `patience=10`: 일정 에포크(예를 들어, 10 에포크) 동안 검증세트에 대한 점수가 향상되지 않으면 자동 종료.\n",
    "    * 에포크 수: 매우 크게 지정해도 됨.\n",
    "* `restore_best_weights=True`: 최상의 모델 복원 기능 설정. 훈련이 끝난 후 최적 가중치 바로 복원."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "early_stopping_cb = keras.callbacks.EralyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, \n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 다양한 콜백함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* keras.callbacks 패키지가 다양한 콜백함수 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사용자정의 콜백함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* keras.callbacks.Callback 클래스 상속\n",
    "* 상속 과정에서 이미 선언된 콜백함수 메서드 중에서 필요한 메서드를 재정의 하면 됨.\n",
    "* 예제: 아래 클래스는 에포크가 끝날 때마다 검증손실과 훈련손실의 비율을 계산하고자 할 경우에 필요한 콜백함수 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
    "        \n",
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 훈련 단계에서 사용될 수 있는 콜백 함수: (`fit()` 메서드에서 활용됨)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* on_train_begin()\n",
    "* on_train_end()\n",
    "* on_epoch_begin()\n",
    "* on_epoch_end()\n",
    "* on_batch_begin()\n",
    "* on_batch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 평가(검증) 단계에서 사용될 수 있는 콜백 함수: `evaluate()`  메서드에서 활용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* on_test_begin()\n",
    "* on_test_end()\n",
    "* on_test_batch_begin()\n",
    "* on_test_batch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 예측 단계에서 사용될 수 있는 콜백 함수: `predict()`  메서드에서 활용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* on_predict_begin()\n",
    "* on_predict_end()\n",
    "* on_predict_batch_begin()\n",
    "* on_predict_batch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 텐서보드 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 텐서보드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 대화식 시각화 도구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 훈련하는 동안의 학습곡선,\n",
    "* 여러 실행 간의 학습곡선 비교,\n",
    "* 계산그래프 시각화,\n",
    "* 훈련통계 분석,\n",
    "* 3D에 사영된 복잡한 다차원 이미지 시각화,\n",
    "* 자동 군집화, 등등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사용방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 콜백 기능을 이용하여 시각화에 필요한 데이터 저장\n",
    "* 이벤트 파일: 텐서보드에 활용되는 이진 로그파일\n",
    "* 로그 디렉토리: 이벤트 파일이 저장되는 디렉토리\n",
    "* 텐서보드 서버: 로그 디렉토리에 저장된 이벤트 파일을 실시간을로 확인하여 변경사항을 업데이트하는 서버"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 로그 디렉토리 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 루트 로그 디렉토리\n",
    "    * 모든 로그 디렉토리의 상위 디렉토리\n",
    "    * 텐서보드 서버가 실시간으로 감시하는 디렉토리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 하위 로그 디렉토리\n",
    "    * 훈련할 때마다 새로운 하위 로그 디렉토리를 생성하여 그곳에 이벤트 파일 저장\n",
    "    * 여러 번 실행한 훈련 결과를 시각화하고 비교 가능해짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-22.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 루트 로그 디렉토리 지정\n",
    "* `get-run_logdir()` 함수\n",
    "    * 훈련 실행할 때 사용될 하위 로그 디렉토리 생성\n",
    "    * 현재 시간 활용하여 매번 새로운 디렉토리 이름 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 루트 로그 디렉토리 지정\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 모델 구성과 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 텐서보드 콜백함수 지정\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 텐서보드 실행 (명령 터미널에서 실행)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ tensorboard --logdir=./my_logs --port=6006\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 인터넷 브라우저에서 `http://localhost:6006` 열면 텐서보드 실행 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"images/ch10/homl10-21.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 신경망 하이퍼파라미터 세부조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 신경망은 조정해야할 하이퍼파라미터가 매우 많음. \n",
    "* 복잡한 네트워크 구조\n",
    "* 층과 뉴런의 수\n",
    "* 활성화 함수, 가중치 초기화 등등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 그리드탐색/랜덤탐색 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 케라스 모델을 사이킷런의 추정기처럼 보여주어야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 회귀 예제: `KerasRegressor` 클래스를 이용하여 케라스 모델을 사이킷런 모델처럼 작동하게 만들 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `KerasRegressor` 클래스의 객체를 생성할 때 아래 `build_model()` 함수와 같이\n",
    "    케라스 모델을 생성하는 함수를 입력해 주어야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 케라스 모델 생성함수 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### KerasRegressor 클래스 활용 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 랜덤탐색 활용 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 더 좋은 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 랜덤탐색 기법은 매우 오래 걸림."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 하이퍼파라미터 최적화에 사용할 수 있는 다양한 라이브러리 개발됨.\n",
    "    * Hyperopt\n",
    "    * Hyperas, kopt, Talos\n",
    "    * Keras Tuner\n",
    "    * Scikit-Optimize(skopt)\n",
    "    * Spearmint\n",
    "    * Hyperband\n",
    "    * Sklearn-Deap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 클라우드 서비스도 활용 가능\n",
    "    * 구글의 AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 하이퍼파라리터 조정 가이드라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 은닉층 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 복잡한 문제 해결의 경우: 심층 신경망이 효율적임.\n",
    "* 과대적합이 발생할 때까지 은닉층 수를 늘려가며 훈련시킬 수 있음.\n",
    "* 수십, 수백층이 필요한 경우도 있음. 하지만 밀집연결이 사용되진 않음. (14장 참조)\n",
    "* 수십, 수백층의 신경망을 처음부터 훈련시키는 대신 훈련된 네트워크를 재사용하는 것이 일반적임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 은닉층의 뉴런 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 일단 필요한 것보다 더 많은 층과 뉴런을 가진 모델로 시작\n",
    "* 과대적합되지 않도록 조기종료나 규제 기법 사용 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $10^{-5}$ 에서 시작하여 $10$까지 조정해보며 실험\n",
    "* 변경 크기는 두 구간의 크기는 500으로 나눈 정도. \n",
    "    * 약, $\\exp(\\log(10^6)/500$ 정도씩 크게해줌."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 옵티마이저"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 고전적인 미니배치 경사하강법 보다 더 좋은 성능의 옵티마이저 사용 가능\n",
    "* 11장 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 배치크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 경우에 따라 다름.\n",
    "* 일반적으로 2-32.\n",
    "* 어떨 때는 8192까지 가능. \n",
    "* 훈련된 성능이 좋지 않을 경우 작은 배치크기 추천."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 활성화함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 은닉층: ReLU 가 일반적.\n",
    "* 출력층: 모델에 따라 다름."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 반복횟수(에포크)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 조기종료 기법을 사용 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 학습률의 의존성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 최적의 학습률은 다른 하이퍼파라미터에 의존적임.\n",
    "* 특히 배치크기에 영양 많이 받음.\n",
    "* 따라서 다른 하이퍼파라이머터를 조정한 경우, 학습률도 조정해야 함."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "핸즈온머신러닝_7장.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
